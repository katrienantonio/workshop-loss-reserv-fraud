##############################################
#  Prep work
##############################################

library(tidyverse)

##############################################
#  Data
##############################################

# get MTPL data set
# install.packages("rstudioapi")
dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dir)
mtpl_orig <- read.table('data/PC_data.txt',
                                   header = TRUE)
mtpl_orig <- as_tibble(mtpl_orig)

## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
str(mtpl_orig)

## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
head(mtpl_orig) 

## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
mtpl_orig %>% slice(1:3) %>% select(-LONG, -LAT) 

## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
mtpl <- mtpl_orig %>%
  # rename all columns 
  rename_all(function(.name) {
    .name %>% 
      # replace all names with the lowercase versions
      tolower 
      # replace all spaces with underscores is also useful, with `str_replace(" ", "-")`
    })
mtpl <- rename(mtpl, expo = exp)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
dim(mtpl)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
mtpl %>% summarize(emp_freq = sum(nclaims) / sum(expo)) 


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
mtpl %>% 
  group_by(sex) %>% 
  summarize(emp_freq = sum(nclaims) / sum(expo)) %>% kable(format = "html") 


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
KULbg <- "#116E8A"
g <- ggplot(mtpl, aes(nclaims)) + theme_bw() + 
     geom_bar(aes(weight = expo), col = KULbg, 
                               fill = KULbg, alpha = 0.5) + 
     labs(y = "Abs freq (in exposure)") +
     ggtitle("MTPL - number of claims")
g


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
g <- ggplot(mtpl, aes(nclaims)) + theme_bw() + 
     geom_bar(aes(y = (..count..)/sum(..count..)), 
             col = KULbg, fill = KULbg, alpha = 0.5) + 
    labs(y = "Relative frequency") +
    ggtitle("MTPL - relative number of claims")
g


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
g <- ggplot(mtpl, aes(nclaims)) + theme_bw() + 
  geom_bar(aes(y = (..count..)), 
           col = KULbg, fill = KULbg, alpha = 0.5) + 
  labs(y = "Absolute frequency") +
  ggtitle("MTPL - relative number of claims")
g

## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
g_dens <- mtpl %>% filter(avg > 0 & avg <= 81000) %>% ggplot(aes(x = avg)) + theme_bw() +
            geom_density(adjust = 3, col = KULbg, fill = KULbg, alpha = 0.5) + xlim(0, 1e4) + ylab("") + xlab("severity") +
            ggtitle("MTPL data - average amount per claim")
g_dens


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
g <- mtpl %>% filter(avg > 0 & avg <= 81000) %>% ggplot(aes(x = avg)) + theme_bw() + xlab("severity") +
  geom_histogram(binwidth = 100, col = KULbg, 
                   fill = KULbg, alpha = 0.5) + xlim(0, 1e4) +
  labs(y = "Frequency histogram")
g


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# get Secura Re data set
secura <- read.table(file="data/SecuraRe.txt", 
                   header = TRUE, sep = "\t")


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
require(gridExtra)
grid.arrange(
  ggplot(secura, aes(Loss)) +
    theme_bw() +
    geom_density(col = KULbg, fill = KULbg, alpha = 0.5) +
    ggtitle('Secura Re - losses') + xlab('loss') + ylab(''),
  ggplot(secura, aes(log(Loss))) +
    theme_bw() +
    geom_density(col = KULbg, fill = KULbg, alpha = 0.5) +
    ggtitle('Secura Re  - losses, log-scale') + xlab('log(loss)') + ylab(''))


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ggplot(secura, aes(Year, Loss)) + theme_bw() + geom_point(colour = KULbg, size = 2, alpha = 0.5) + 
  ggtitle('Secura Re - losses arriving over time')


##############################################
#  Frequency models
##############################################


## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# explore (a,b,0) relation
empirical <- mtpl$nclaims %>% 
  table %>% prop.table %>% as.numeric
empirical


## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
k <- 1:(length(empirical) - 1)
ab0_relation <- empirical[k+1] / empirical[k] * k  


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ab0_data <- tibble(k = k, ab0_rel = ab0_relation)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ggplot(data.frame(k = k, relation = ab0_relation), 
       aes(x = k, y = relation)) +
  theme_bw() + ylab('frac') +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE)


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# empirical mean
mean(mtpl$nclaims)
sum(mtpl$nclaims)/sum(mtpl$expo)
weighted.mean(mtpl$nclaims/mtpl$expo, mtpl$expo)
mtpl %>% summarize(emp_freq = sum(nclaims) / sum(expo)) 


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# empirical mean and variance
m <- sum(mtpl$nclaims)/sum(mtpl$expo)
m
var <- sum((mtpl$nclaims - m * mtpl$expo)^2)/
                sum(mtpl$expo)
var


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# fit POI distribution
library(MASS)
fitdistr(mtpl$nclaims, "poisson")


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
freq_glm_poi <- glm(nclaims ~ 1, offset = log(expo), 
                  family = poisson(link = "log"), 
                  data = mtpl)
freq_glm_poi %>% broom::tidy() 


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
neg_loglik_pois <- function(par, freq, expo){
  lambda <- expo*exp(par)
  -sum(dpois(freq, lambda, log = T))
}
sol_poi <- nlm(neg_loglik_pois, 1, hessian = TRUE, 
               freq = mtpl$nclaims, expo = mtpl$expo)


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
exp(sol_poi$estimate)
sqrt(diag(solve(sol_poi$hessian))) 
sol_poi$minimum


## ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# fit NB distribution
freq_glm_nb <- glm.nb(nclaims ~ 1 + offset(log(expo)), 
                  link = log,
                  data = mtpl)
freq_glm_nb %>% broom::tidy()


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
freq_glm_nb$theta
freq_glm_nb$SE.theta


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
summary(freq_glm_nb)


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
neg_loglik_nb <- function(par, freq, expo){
  mu <- expo*exp(par[1])
  r <- exp(par[2])
  -sum(dnbinom(freq, size = r, mu = mu, log = TRUE))
}
sol_nb <- nlm(neg_loglik_nb, c(1, 1), hessian = TRUE, 
              freq = mtpl$nclaims, expo = mtpl$expo)


## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sol_nb$estimate


## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
exp(sol_nb$estimate)
sqrt(diag(solve(sol_nb$hessian))) 
sol_nb$minimum


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
exp(sol_nb$estimate[1]) + 
(exp(sol_nb$estimate[1])^2)/(exp(sol_nb$estimate[2]))


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
AIC_poi <- 2*length(sol_poi$estimate) + 2*sol_poi$minimum
AIC_nb <- 2*length(sol_nb$estimate) + 2*sol_nb$minimum
c(AIC_nb = AIC_nb, AIC_poi = AIC_poi)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
observed_count = rep(0, 5)
model_based_count = rep(0, 5)

for(i in 1:5) {
  observed_count[i] = sum(mtpl$nclaims == i-1)
  model_based_count[i] = sum(dnbinom(i-1, size = freq_glm_nb$theta, mu = fitted(freq_glm_nb)))
}

data.frame(frequency = 0:4,
           observed_count = observed_count,
           model_based_count = round(model_based_count))



## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# fit ZIP distribution
library(pscl)
f_ZIP <- zeroinfl(nclaims ~ 1, offset = log(expo), 
                  dist = "poisson", data = mtpl)
summary(f_ZIP)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
f_ZIP$coefficients
(f_ZIP_lambda <- exp(as.numeric(f_ZIP$coefficients[1])))
(f_ZIP_pi <- exp(as.numeric(f_ZIP$coefficients[2]))/(1+exp(as.numeric(f_ZIP$coefficients[2]))))
(AIC_ZIP <- 2*length(f_ZIP$coefficients) - 2*f_ZIP$loglik)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(ZIP_mean <- (1-f_ZIP_pi)*f_ZIP_lambda)
(ZIP_var <- (1-f_ZIP_pi)*f_ZIP_lambda*(1+f_ZIP_pi*f_ZIP_lambda))


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
neg_loglik_ZIP <- function(par, freq, expo){
  lambda <- expo*exp(par[1])
  p <- exp(par[2])/(1+exp(par[2]))
  
  -sum((freq == 0) * (log(p + (1-p)*dpois(0, lambda, log = FALSE)))) - 
    sum((freq != 0) * (log((1-p)) + dpois(freq, lambda, log = TRUE)))
}

sol_ZIP <- nlm(neg_loglik_ZIP, c(1, 1), hessian = TRUE, 
              freq = mtpl$nclaims, expo = mtpl$expo)
sol_ZIP$estimate


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(sol_ZIP_se <- sqrt(diag(solve(sol_ZIP$hessian))))


##############################################
#  Severity models
##############################################


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
library(ReIns)
ReIns::MeanExcess(secura$Loss)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ReIns::ExpQQ(secura$Loss)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ReIns::ParetoQQ(secura$Loss)

## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
H <- ReIns::Hill(secura$Loss, k = FALSE, lwd = 2, plot = TRUE, main = "")

## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
H <- ReIns::Hill(secura$Loss, k = TRUE, lwd = 2, plot = TRUE, main = "")


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
H <- ReIns::Hill(secura$Loss, lwd = 2, plot = TRUE, main = "")
kopt <- ReIns::Hill.kopt(secura$Loss, plot = FALSE)$kopt
abline(v = kopt, lwd = 2, lty = 2)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# sample size
n <- length(secura$Loss)
n

# Hill estimator
kopt <- Hill.kopt(secura$Loss, plot = FALSE)$kopt
kopt

# chosen threshold
threshold <- sort(secura$Loss)[n - kopt]
threshold

# estimate for gamma using Hill estimator
gamma <- H$gamma[kopt]
gamma

## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(p <- sum(secura$Loss <= threshold)/n)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
(n-kopt)/n


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
sh <- 1200000 # shift
I <- secura$Loss <= threshold # indicator

neg.loglik <- function(par) {
	lambda <- exp(par[1]); alpha <- exp(par[2]) 
	# likelihood
	L <- I * (n-kopt)/n * lambda * exp(-lambda*(secura$Loss-sh))/(1 - exp(-lambda*(threshold-sh))) + 
		(1-I) * kopt/n * alpha * (secura$Loss)^(-alpha-1)/(threshold)^(-alpha)
	# negative log-likelihood
	-sum(log(L)) 
}

m1 <- mean(secura$Loss)
par.init <- c(1/(m1-sh), 1/m1)
oo <- nlm(neg.loglik, log(par.init))
(lambda <- exp(oo$estimate[1])) 
(alpha <- exp(oo$estimate[2]))
(gamma <- 1/alpha)


## ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# CDF for Exp-Pa splicing model
ExpPa_cdf <- function(x, sh, threshold, lambda, gamma) {
  
  p <- numeric(length(x))
  
  p[x <= threshold] <- (n - kopt) / n * pexp(x[x <= threshold] - sh, rate = lambda) / 
                                        pexp(threshold - sh, rate = lambda)
  
  p[x > threshold] <- 1 - kopt / n * (x[x > threshold] / threshold) ^ (-1/gamma)
  
  return(p)
}


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Plot empirical CDF and fitted CDF
plot(ecdf(secura$Loss), do.points = FALSE, xlab = "CDF", xlim = c(sh, 7 * 10^6), lwd = 2, main = "CDF: empirical and fitted")
lines(sort(secura$Loss), ExpPa_cdf(sort(secura$Loss), sh, threshold, lambda, gamma), lty = 2, lwd=2)
legend("bottomright", c("Empirical CDF", "Fitted CDF"), lty = c(1, 2), lwd = 2)


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Fit ME model using internal function from 
# ReIns package
MEfit_sec <- ReIns:::.ME_tune(secura$Loss, 
                              trunclower = sh, 
                              criterium = "BIC", 
                              M = 10, 
                              s = 1:40)$best_model

# Fitted parameters
MEfit_sec$alpha
MEfit_sec$shape
MEfit_sec$theta


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Histogram
truehist(secura$Loss, nbins = 40, ylim = c(0, 8e-07), xlab = "Claim size", ylab = "Density")
curve(ReIns:::.ME_density(x, theta = MEfit_sec$theta, shape = MEfit_sec$shape, 
                          alpha = MEfit_sec$alpha, trunclower = sh), 
      from = 10^6, to = 8 * 10^06, n = 10000, add = TRUE, col = "red", lwd = 2)
legend('topright', legend = c("ME Density", "Observed Relative Frequency"),
       col = c("red", "cyan"), pch = c(NA,15), pt.cex = 2, lty = c(1,NA), lwd = c(2,NA))


## -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ME_VaR <- Vectorize(ReIns:::.ME_VaR, 
                    vectorize.args = "p")

# QQ-plot
plot(ME_VaR((1:n) / (n+1), theta = MEfit_sec$theta, 
            shape = MEfit_sec$shape, 
            alpha = MEfit_sec$alpha, 
            trunclower = sh), 
     sort(secura$Loss), 
     main = "ME QQ-plot", 
     xlab = "Fitted quantiles", 
     ylab = "Empirical quantiles")
abline(0, 1)


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Fit ME-Pa splicing model
splicefit_sec <- ReIns::SpliceFitPareto(secura$Loss, 
                                        tsplice = threshold, 
                                        M = 10, 
                                        trunclower = sh)

# Summary
summary(splicefit_sec)


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# ECDF plot
x <- seq(10^6, 10^7, 10^3)
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2)
abline(v = splicefit_sec$t, lty = 2, lwd = 2)

## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Zoomed ECDF plot
SpliceECDF(x, secura$Loss, splicefit_sec, lwd = 2, ylim = c(0,0.3))
abline(v = splicefit_sec$t, lty = 2, lwd = 2)


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# PP-plot
SplicePP(secura$Loss, splicefit_sec)


## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# PP-plot with minus log-scale
SplicePP(secura$Loss, splicefit_sec, log = TRUE)


## ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# QQ-plot
SpliceQQ(secura$Loss, splicefit_sec)


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Quantile function for Exp-Pa splicing model
ExpPa_quantile <- function(p, sh, threshold, lambda, gamma) {
  
  pi <- (n-kopt)/n
  
  x <- numeric(length(p))
  
  x[p <= pi] <- qexp(p[p <= pi] / pi * (pexp(threshold, rate = lambda) - pexp(sh, rate = lambda)) + 
                       pexp(sh, rate = lambda), rate = lambda)
  
  x[p > pi] <- threshold * (1 - (p[p > pi] - pi) / (1-pi))^(-gamma)

  return(x)
}


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# calculate VaR
ExpPa_quantile(0.95, sh, threshold, lambda, gamma)


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
ExpPa_cdf(ExpPa_quantile(0.95, sh, 
                         threshold, 
                         lambda, gamma), 
          sh, threshold, lambda, gamma)


## -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# calculate CTE
qf <- function(p) {
  ExpPa_quantile(p, sh, threshold, lambda, gamma) 
}

int <- integrate(qf, lower = 0.95, upper = 1) 
int$value / 0.05

